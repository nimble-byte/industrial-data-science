{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Since this is a handin exercise I will shortly outline the setup required for this notebook to run (assuming I can only hand in the `.ipynb` file). The notebook pulls from the dependencies in the first code block. To install all relevant libraries run (assuming you have `jupyter` installed):\n",
    "\n",
    "```shell\n",
    "python -m pip install pandas tensorflow sklearn\n",
    "```\n",
    "\n",
    "Additionally it required the data and labels to be available as follows:\n",
    "1. the batch data is located in a `data` folder next to the notebook\n",
    "2. the label information is stored as `labels.csv` next to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "First the data needs to be loaded (first codeblock) and then go through some minor transformations before building the training, test and validation datasets. For this purpose all data is loaded into a flat dataframe that includes the batch and corresponding label in addition to the actual features `zeit`, `sensorid` und `messwert`. In preparation for the model training the `zeit` is transformed to float values and the data types of `sensorid` and `label` are adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the labels.csv\n",
    "labels = pd.read_csv('labels.csv', index_col=0)\n",
    "labels = labels.sort_values('id')\n",
    "\n",
    "# grab filenames from the data directory\n",
    "filenames = os.listdir('data')\n",
    "filenames.sort()\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# parse and concatenate all csv files into df\n",
    "for filename in filenames:\n",
    "  if filename.endswith('.csv'):\n",
    "    batch = pd.read_csv(os.path.join('data',filename), index_col=0)\n",
    "    batch['batch'] = int(filename.replace('.csv', ''))\n",
    "    dataframes.append(batch)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# clean up original dataframes\n",
    "del dataframes\n",
    "\n",
    "# add label column (if it is not already available)\n",
    "if (not 'label' in df.columns):\n",
    "  df = df.merge(labels, left_on=[\"batch\"], right_on=[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_float(inputstr):\n",
    "  hours, minutes, seconds = map(float, inputstr.split(':'))\n",
    "\n",
    "  # return hours * 3600 + minutes * 60 + seconds\n",
    "  # this is sufficient because hours should always be 0\n",
    "  return minutes * 60 + seconds\n",
    "\n",
    "if (not df['sensorid'].dtype == 'int'):\n",
    "  df['sensorid'] = df['sensorid'].astype('int')\n",
    "if (not df['label'].dtype == 'category'):\n",
    "  df['label'] = df['label'].astype('category')\n",
    "if (not df['zeit'].dtype == 'float64'):\n",
    "  df['zeit'] = df['zeit'].apply(time_to_float)\n",
    "\n",
    "# print(df[:10])\n",
    "# print(labels[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Data\n",
    "\n",
    "This step was only introduced once I decided to use a recurrent neural network (specifically an LSTM). The flat dataframe created before has to be broken down into small sequences that will be fed to the model. As to not created sequences with mixed labels, the data was grouped by `batch`. Additionally it is important that each batch is sorted by `zeit` since order of readings in sequences is relevant. After splitting each batch into equally sized sequences (dropping any additional readings at the end that were not able to make a full sequence), the data is split into training, test and validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 256\n",
    "\n",
    "sequences = []\n",
    "sequence_labels = []\n",
    "\n",
    "# build sequences based on chosen sequence length\n",
    "for batch, readings in df.groupby('batch'):\n",
    "  readings = readings.sort_values('zeit')\n",
    "  for i in range(0, len(readings) - SEQUENCE_LENGTH, SEQUENCE_LENGTH):\n",
    "    sequence = readings.iloc[i:i + SEQUENCE_LENGTH]\n",
    "    sequences.append(sequence[['zeit', 'sensorid', 'messwert']].values)\n",
    "    sequence_labels.append(sequence['label'].values[0])\n",
    "\n",
    "# transform to numpy arrays for tensorflow\n",
    "sequences = np.array(sequences)\n",
    "sequence_labels = np.array(sequence_labels)\n",
    "\n",
    "# split into train, validation and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, sequence_labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling & Training\n",
    "\n",
    "The initial plan was to train a simple NN, that is fed `zeit`, `sensorid` and `messwert` as features to predict the label, but it became apparent quickly, that this approach would not lead to the reuqired accurracy. After some additional research, I settled on an LSTM which is able to detect and learn patterns in the sequences. Batch size and the number of LSTM units was determined using a grid search and running it over night to determine the best `SEQUENCE_LENGTH`, `LSTM_UNITS` and `BATCH_SIZE`. The grid search revealed, that among the chosen options the largest options for `SEQUENCE_LENGTH` and `LSTM_UNITS` performed the best with an accuracy of about 75%.\n",
    "\n",
    "The model itself is implemented as Sequential Model using Tensorflow keras. It consists of 2 layers:\n",
    "\n",
    "- the aforementioned LSTM layer, handling the input and pattern detection\n",
    "- a densely connected layer using softmax activations to produce the predictions\n",
    "\n",
    "The model was then trained using the adam optimiser and set up for early training termination, based on the validation loss each round to prevent overfitting. Each 8 epochs the model weights were saved, as a safety measure should model training crash at any point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "153/153 [==============================] - 38s 245ms/step - loss: 1.1125 - accuracy: 0.3380 - val_loss: 1.1030 - val_accuracy: 0.3454\n",
      "Epoch 2/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 1.1010 - accuracy: 0.3555 - val_loss: 1.1038 - val_accuracy: 0.3257\n",
      "Epoch 3/256\n",
      "153/153 [==============================] - 37s 244ms/step - loss: 1.0995 - accuracy: 0.3536 - val_loss: 1.1062 - val_accuracy: 0.3462\n",
      "Epoch 4/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 1.0988 - accuracy: 0.3558 - val_loss: 1.1026 - val_accuracy: 0.3355\n",
      "Epoch 5/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 1.0982 - accuracy: 0.3560 - val_loss: 1.1016 - val_accuracy: 0.3413\n",
      "Epoch 6/256\n",
      "153/153 [==============================] - 38s 247ms/step - loss: 1.0946 - accuracy: 0.3724 - val_loss: 1.1006 - val_accuracy: 0.3351\n",
      "Epoch 7/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 1.0944 - accuracy: 0.3733 - val_loss: 1.0977 - val_accuracy: 0.3626\n",
      "Epoch 8/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 1.0950 - accuracy: 0.3718 - val_loss: 1.0988 - val_accuracy: 0.3470\n",
      "Epoch 9/256\n",
      "153/153 [==============================] - 38s 246ms/step - loss: 1.0926 - accuracy: 0.3669 - val_loss: 1.1042 - val_accuracy: 0.3437\n",
      "Epoch 10/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 1.0927 - accuracy: 0.3701 - val_loss: 1.1033 - val_accuracy: 0.3400\n",
      "Epoch 11/256\n",
      "153/153 [==============================] - 37s 245ms/step - loss: 1.0928 - accuracy: 0.3741 - val_loss: 1.0980 - val_accuracy: 0.3654\n",
      "Epoch 12/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 1.0924 - accuracy: 0.3763 - val_loss: 1.1026 - val_accuracy: 0.3421\n",
      "Epoch 13/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 1.0898 - accuracy: 0.3759 - val_loss: 1.1019 - val_accuracy: 0.3568\n",
      "Epoch 14/256\n",
      "153/153 [==============================] - 37s 243ms/step - loss: 1.0918 - accuracy: 0.3808 - val_loss: 1.0976 - val_accuracy: 0.3572\n",
      "Epoch 15/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 1.0884 - accuracy: 0.3846 - val_loss: 1.0953 - val_accuracy: 0.3658\n",
      "Epoch 16/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 1.0868 - accuracy: 0.3797 - val_loss: 1.0993 - val_accuracy: 0.3523\n",
      "Epoch 17/256\n",
      "153/153 [==============================] - 37s 243ms/step - loss: 1.0865 - accuracy: 0.3834 - val_loss: 1.0929 - val_accuracy: 0.3703\n",
      "Epoch 18/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 1.0859 - accuracy: 0.3880 - val_loss: 1.0891 - val_accuracy: 0.3777\n",
      "Epoch 19/256\n",
      "153/153 [==============================] - 37s 243ms/step - loss: 1.0847 - accuracy: 0.3846 - val_loss: 1.0923 - val_accuracy: 0.3728\n",
      "Epoch 20/256\n",
      "153/153 [==============================] - 37s 244ms/step - loss: 1.0817 - accuracy: 0.3929 - val_loss: 1.1065 - val_accuracy: 0.3654\n",
      "Epoch 21/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 1.0847 - accuracy: 0.3927 - val_loss: 1.0871 - val_accuracy: 0.3785\n",
      "Epoch 22/256\n",
      "153/153 [==============================] - 37s 244ms/step - loss: 1.0779 - accuracy: 0.4072 - val_loss: 1.0871 - val_accuracy: 0.3826\n",
      "Epoch 23/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 1.0784 - accuracy: 0.4051 - val_loss: 1.0888 - val_accuracy: 0.3687\n",
      "Epoch 24/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 1.0747 - accuracy: 0.4102 - val_loss: 1.0937 - val_accuracy: 0.3736\n",
      "Epoch 25/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 1.0723 - accuracy: 0.4085 - val_loss: 1.0831 - val_accuracy: 0.3884\n",
      "Epoch 26/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 1.0683 - accuracy: 0.4130 - val_loss: 1.0753 - val_accuracy: 0.4101\n",
      "Epoch 27/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 1.0647 - accuracy: 0.4197 - val_loss: 1.0682 - val_accuracy: 0.4306\n",
      "Epoch 28/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 1.0509 - accuracy: 0.4460 - val_loss: 1.0566 - val_accuracy: 0.4342\n",
      "Epoch 29/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 1.0513 - accuracy: 0.4457 - val_loss: 1.0934 - val_accuracy: 0.3880\n",
      "Epoch 30/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 1.0334 - accuracy: 0.4690 - val_loss: 1.0237 - val_accuracy: 0.4818\n",
      "Epoch 31/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 1.0171 - accuracy: 0.4834 - val_loss: 1.0017 - val_accuracy: 0.4977\n",
      "Epoch 32/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.9873 - accuracy: 0.4994 - val_loss: 0.9663 - val_accuracy: 0.4961\n",
      "Epoch 33/256\n",
      "153/153 [==============================] - 37s 243ms/step - loss: 0.9181 - accuracy: 0.5500 - val_loss: 0.8752 - val_accuracy: 0.5326\n",
      "Epoch 34/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 0.9078 - accuracy: 0.5346 - val_loss: 0.7983 - val_accuracy: 0.5924\n",
      "Epoch 35/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 0.8264 - accuracy: 0.5894 - val_loss: 0.7715 - val_accuracy: 0.6030\n",
      "Epoch 36/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 0.8063 - accuracy: 0.5928 - val_loss: 0.9477 - val_accuracy: 0.4764\n",
      "Epoch 37/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 0.7657 - accuracy: 0.6206 - val_loss: 0.6806 - val_accuracy: 0.6546\n",
      "Epoch 38/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.7176 - accuracy: 0.6431 - val_loss: 0.6913 - val_accuracy: 0.6272\n",
      "Epoch 39/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.7070 - accuracy: 0.6457 - val_loss: 0.7023 - val_accuracy: 0.6411\n",
      "Epoch 40/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.6981 - accuracy: 0.6483 - val_loss: 0.9217 - val_accuracy: 0.5825\n",
      "Epoch 41/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.6743 - accuracy: 0.6626 - val_loss: 0.6629 - val_accuracy: 0.6522\n",
      "Epoch 42/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 0.6494 - accuracy: 0.6829 - val_loss: 0.6111 - val_accuracy: 0.7054\n",
      "Epoch 43/256\n",
      "153/153 [==============================] - 36s 239ms/step - loss: 0.6575 - accuracy: 0.6783 - val_loss: 0.6757 - val_accuracy: 0.6268\n",
      "Epoch 44/256\n",
      "153/153 [==============================] - 37s 243ms/step - loss: 0.6428 - accuracy: 0.6831 - val_loss: 0.5916 - val_accuracy: 0.7243\n",
      "Epoch 45/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.6736 - accuracy: 0.6636 - val_loss: 0.6326 - val_accuracy: 0.6862\n",
      "Epoch 46/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 0.6465 - accuracy: 0.6821 - val_loss: 0.6288 - val_accuracy: 0.7050\n",
      "Epoch 47/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.6143 - accuracy: 0.7023 - val_loss: 0.6272 - val_accuracy: 0.7054\n",
      "Epoch 48/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.6323 - accuracy: 0.6918 - val_loss: 0.5879 - val_accuracy: 0.7231\n",
      "Epoch 49/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.6028 - accuracy: 0.7073 - val_loss: 0.5781 - val_accuracy: 0.7190\n",
      "Epoch 50/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 0.5963 - accuracy: 0.7103 - val_loss: 0.5948 - val_accuracy: 0.7145\n",
      "Epoch 51/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 0.5894 - accuracy: 0.7107 - val_loss: 0.5815 - val_accuracy: 0.7268\n",
      "Epoch 52/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.6081 - accuracy: 0.7007 - val_loss: 0.7602 - val_accuracy: 0.6137\n",
      "Epoch 53/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 0.5932 - accuracy: 0.7108 - val_loss: 0.5938 - val_accuracy: 0.6948\n",
      "Epoch 54/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.5724 - accuracy: 0.7250 - val_loss: 0.6086 - val_accuracy: 0.6858\n",
      "Epoch 55/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.5888 - accuracy: 0.7133 - val_loss: 0.5554 - val_accuracy: 0.7206\n",
      "Epoch 56/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 0.5657 - accuracy: 0.7239 - val_loss: 0.5644 - val_accuracy: 0.7149\n",
      "Epoch 57/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 0.5905 - accuracy: 0.7089 - val_loss: 0.5520 - val_accuracy: 0.7304\n",
      "Epoch 58/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.5708 - accuracy: 0.7227 - val_loss: 0.5607 - val_accuracy: 0.7325\n",
      "Epoch 59/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.5663 - accuracy: 0.7234 - val_loss: 0.5842 - val_accuracy: 0.6841\n",
      "Epoch 60/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 0.5970 - accuracy: 0.7053 - val_loss: 0.5458 - val_accuracy: 0.7296\n",
      "Epoch 61/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.5532 - accuracy: 0.7355 - val_loss: 0.5766 - val_accuracy: 0.7153\n",
      "Epoch 62/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.5623 - accuracy: 0.7281 - val_loss: 0.5939 - val_accuracy: 0.7206\n",
      "Epoch 63/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 0.5549 - accuracy: 0.7272 - val_loss: 0.5802 - val_accuracy: 0.6932\n",
      "Epoch 64/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.5502 - accuracy: 0.7335 - val_loss: 0.5333 - val_accuracy: 0.7390\n",
      "Epoch 65/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.5443 - accuracy: 0.7339 - val_loss: 0.8285 - val_accuracy: 0.6194\n",
      "Epoch 66/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.5562 - accuracy: 0.7329 - val_loss: 0.5588 - val_accuracy: 0.7112\n",
      "Epoch 67/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 0.5511 - accuracy: 0.7336 - val_loss: 0.5545 - val_accuracy: 0.7202\n",
      "Epoch 68/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 0.5606 - accuracy: 0.7235 - val_loss: 0.7481 - val_accuracy: 0.6067\n",
      "Epoch 69/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.5500 - accuracy: 0.7329 - val_loss: 0.5378 - val_accuracy: 0.7337\n",
      "Epoch 70/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 0.5642 - accuracy: 0.7277 - val_loss: 0.5652 - val_accuracy: 0.7218\n",
      "Epoch 71/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.5526 - accuracy: 0.7258 - val_loss: 0.5518 - val_accuracy: 0.7136\n",
      "Epoch 72/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 0.5649 - accuracy: 0.7211 - val_loss: 0.5405 - val_accuracy: 0.7235\n",
      "Epoch 73/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.5281 - accuracy: 0.7407 - val_loss: 0.5451 - val_accuracy: 0.7222\n",
      "Epoch 74/256\n",
      "153/153 [==============================] - 38s 247ms/step - loss: 0.5351 - accuracy: 0.7374 - val_loss: 0.5324 - val_accuracy: 0.7358\n",
      "Epoch 75/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.5421 - accuracy: 0.7362 - val_loss: 0.5207 - val_accuracy: 0.7431\n",
      "Epoch 76/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.5415 - accuracy: 0.7379 - val_loss: 0.5695 - val_accuracy: 0.7255\n",
      "Epoch 77/256\n",
      "153/153 [==============================] - 37s 245ms/step - loss: 0.5447 - accuracy: 0.7360 - val_loss: 0.5472 - val_accuracy: 0.7149\n",
      "Epoch 78/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.5473 - accuracy: 0.7341 - val_loss: 0.5612 - val_accuracy: 0.6989\n",
      "Epoch 79/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 0.5428 - accuracy: 0.7363 - val_loss: 0.5245 - val_accuracy: 0.7399\n",
      "Epoch 80/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 0.5408 - accuracy: 0.7348 - val_loss: 0.6027 - val_accuracy: 0.7009\n",
      "Epoch 81/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 0.5367 - accuracy: 0.7413 - val_loss: 0.5395 - val_accuracy: 0.7235\n",
      "Epoch 82/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 0.5389 - accuracy: 0.7391 - val_loss: 0.5657 - val_accuracy: 0.7206\n",
      "Epoch 83/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.5182 - accuracy: 0.7528 - val_loss: 0.6662 - val_accuracy: 0.6780\n",
      "Epoch 84/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.5339 - accuracy: 0.7446 - val_loss: 0.5256 - val_accuracy: 0.7403\n",
      "Epoch 85/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.5364 - accuracy: 0.7410 - val_loss: 0.6109 - val_accuracy: 0.6919\n",
      "Epoch 86/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 0.5131 - accuracy: 0.7502 - val_loss: 0.5297 - val_accuracy: 0.7378\n",
      "Epoch 87/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.5185 - accuracy: 0.7448 - val_loss: 0.5927 - val_accuracy: 0.7083\n",
      "Epoch 88/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.5332 - accuracy: 0.7427 - val_loss: 0.5384 - val_accuracy: 0.7304\n",
      "Epoch 89/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 0.5121 - accuracy: 0.7540 - val_loss: 0.5807 - val_accuracy: 0.7087\n",
      "Epoch 90/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 0.5388 - accuracy: 0.7413 - val_loss: 0.5316 - val_accuracy: 0.7313\n",
      "Epoch 91/256\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.7485Restoring model weights from the end of the best epoch: 75.\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 0.5157 - accuracy: 0.7485 - val_loss: 0.5694 - val_accuracy: 0.7186\n",
      "Epoch 91: early stopping\n"
     ]
    }
   ],
   "source": [
    "# make key hyperparameters accessible and easy to tune\n",
    "BATCH_SIZE = 64\n",
    "LSTM_UNITS = 256\n",
    "\n",
    "# calculate how many times the model will adjust it's weights per epoch (used for saving checkpoints)\n",
    "SAVE_FREQ = math.ceil(len(X_train) / BATCH_SIZE)\n",
    "num_features = X_train.shape[2]\n",
    "num_classes = len(labels['label'].unique())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(LSTM_UNITS, input_shape=(SEQUENCE_LENGTH, num_features)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "cp_cb = ModelCheckpoint(filepath='.checkpoints/cp-{epoch:03d}.ckpt', save_weights_only=True, save_freq=8*SAVE_FREQ)\n",
    "stp_cb = EarlyStopping(monitor='val_loss', patience=16, restore_best_weights=True, min_delta=1e-4, start_from_epoch=32, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=256, batch_size=BATCH_SIZE, callbacks=[cp_cb, stp_cb], validation_data=(X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "model.save(f'models/lstm_{LSTM_UNITS}-seq_{SEQUENCE_LENGTH}-batch_{BATCH_SIZE}.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Last thing to do is verify the models accuracy using the previously split test data. In addition to verifying the model accurary, I used a confusion matrix to inform the prominent prediction errors, which could be used to improve additional model iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 73.82%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model from file instead of training\n",
    "# model = tf.keras.models.load_model(\"model.keras\")\n",
    "\n",
    "# Quick variant used for model training and tuning\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=None)\n",
    "print(\"Model accuracy: {:5.2f}%\".format(100 * acc))\n",
    "\n",
    "# Build confusion matrix\n",
    "pred = model.predict(X_test, verbose=None)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels[\"label\"].unique())\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm,  display_labels=labels[\"label\"].unique())\n",
    "cm_disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Notes\n",
    "\n",
    "The model trained and presented above needs additional work to be able to be sensibly deployed to production. Three major aspects have to be considered:\n",
    "\n",
    "1. The model currently requires specially formatted input, that is different from the `.csv` batch data, that was presented for training. Luckily trainsforming a single batch into 256 reading sequences is fairly simple and the code from above can be reused. Assuming the data of a batch was parsed into the variable `batch` the following snipped can be included as part of the model pipeline.\n",
    "```python\n",
    "batch = batch.sort_values('zeit')\n",
    "for i in range(0, len(batch) - SEQUENCE_LENGTH, SEQUENCE_LENGTH):\n",
    "  sequence = batch.iloc[i:i + SEQUENCE_LENGTH]\n",
    "  sequences.append(sequence[['zeit', 'sensorid', 'messwert']].values)\n",
    "```\n",
    "\n",
    "2. The predictions made by the model (with ~75% accuracy) are for 256 reading sequences instead for a full batch (which I assume to be the goal in deployment). To predict a full batch a simple method like simple majority voting based on the predictions for sequences can be applied to determine the prediction for the batch.\n",
    "\n",
    "3. While the best model has an accuracy of ~75%, it is worthy to point out, that several other models with smaller sequences and fewer LSTM units have achieved almost similar results. In a real world deployment model size and complexity should be considered. I will hand in said best configuration, but at the cost of 3-4% accuracy a significantly smaller model could be used alternatively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
