{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the labels.csv\n",
    "labels = pd.read_csv('labels.csv', index_col=0)\n",
    "labels = labels.sort_values('id')\n",
    "\n",
    "# grab filenames from the data directory\n",
    "filenames = os.listdir('data')\n",
    "filenames.sort()\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# parse and concatenate all csv files into df\n",
    "for filename in filenames:\n",
    "  if filename.endswith('.csv'):\n",
    "    batch = pd.read_csv(os.path.join('data',filename), index_col=0)\n",
    "    batch['batch'] = int(filename.replace('.csv', ''))\n",
    "    dataframes.append(batch)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# clean up original dataframes\n",
    "del dataframes\n",
    "\n",
    "# add label column (if it is not already available)\n",
    "if (not 'label' in df.columns):\n",
    "  df = df.merge(labels, left_on=[\"batch\"], right_on=[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_float(inputstr):\n",
    "  hours, minutes, seconds = map(float, inputstr.split(':'))\n",
    "\n",
    "  # return hours * 3600 + minutes * 60 + seconds\n",
    "  # this is sufficient because hours should always be 0\n",
    "  return minutes * 60 + seconds\n",
    "\n",
    "if (not df['sensorid'].dtype == 'int'):\n",
    "  df['sensorid'] = df['sensorid'].astype('int')\n",
    "if (not df['label'].dtype == 'category'):\n",
    "  df['label'] = df['label'].astype('category')\n",
    "if (not df['zeit'].dtype == 'float64'):\n",
    "  df['zeit'] = df['zeit'].apply(time_to_float)\n",
    "\n",
    "# print(df[:10])\n",
    "# print(labels[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 256\n",
    "\n",
    "sequences = []\n",
    "sequence_labels = []\n",
    "\n",
    "# build sequences based on chosen sequence length\n",
    "for batch, readings in df.groupby('batch'):\n",
    "  readings = readings.sort_values('zeit')\n",
    "  for i in range(0, len(readings) - SEQUENCE_LENGTH, SEQUENCE_LENGTH):\n",
    "    sequence = readings.iloc[i:i + SEQUENCE_LENGTH]\n",
    "    sequences.append(sequence[['zeit', 'sensorid', 'messwert']].values)\n",
    "    sequence_labels.append(sequence['label'].values[0])\n",
    "\n",
    "# transform to numpy arrays for tensorflow\n",
    "sequences = np.array(sequences)\n",
    "sequence_labels = np.array(sequence_labels)\n",
    "\n",
    "# split into train, validation and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, sequence_labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "153/153 [==============================] - 37s 238ms/step - loss: 1.1101 - accuracy: 0.3501 - val_loss: 1.1035 - val_accuracy: 0.3281\n",
      "Epoch 2/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 1.1027 - accuracy: 0.3444 - val_loss: 1.1030 - val_accuracy: 0.3376\n",
      "Epoch 3/256\n",
      "153/153 [==============================] - 35s 232ms/step - loss: 1.1005 - accuracy: 0.3506 - val_loss: 1.1060 - val_accuracy: 0.3421\n",
      "Epoch 4/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 1.1006 - accuracy: 0.3459 - val_loss: 1.1044 - val_accuracy: 0.3454\n",
      "Epoch 5/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0991 - accuracy: 0.3487 - val_loss: 1.1030 - val_accuracy: 0.3138\n",
      "Epoch 6/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 1.0996 - accuracy: 0.3562 - val_loss: 1.1096 - val_accuracy: 0.3302\n",
      "Epoch 7/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 1.0974 - accuracy: 0.3537 - val_loss: 1.1032 - val_accuracy: 0.3429\n",
      "Epoch 8/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0954 - accuracy: 0.3608 - val_loss: 1.1053 - val_accuracy: 0.3552\n",
      "Epoch 9/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 1.0970 - accuracy: 0.3591 - val_loss: 1.1074 - val_accuracy: 0.3200\n",
      "Epoch 10/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 1.0942 - accuracy: 0.3637 - val_loss: 1.1027 - val_accuracy: 0.3449\n",
      "Epoch 11/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0949 - accuracy: 0.3662 - val_loss: 1.1015 - val_accuracy: 0.3425\n",
      "Epoch 12/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 1.0945 - accuracy: 0.3656 - val_loss: 1.1013 - val_accuracy: 0.3400\n",
      "Epoch 13/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 1.0935 - accuracy: 0.3654 - val_loss: 1.1002 - val_accuracy: 0.3359\n",
      "Epoch 14/256\n",
      "153/153 [==============================] - 35s 231ms/step - loss: 1.0931 - accuracy: 0.3709 - val_loss: 1.1022 - val_accuracy: 0.3531\n",
      "Epoch 15/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 1.0935 - accuracy: 0.3725 - val_loss: 1.1067 - val_accuracy: 0.3277\n",
      "Epoch 16/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 1.0940 - accuracy: 0.3669 - val_loss: 1.1070 - val_accuracy: 0.3458\n",
      "Epoch 17/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 1.0957 - accuracy: 0.3626 - val_loss: 1.1025 - val_accuracy: 0.3413\n",
      "Epoch 18/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 1.0924 - accuracy: 0.3658 - val_loss: 1.1016 - val_accuracy: 0.3281\n",
      "Epoch 19/256\n",
      "153/153 [==============================] - 36s 232ms/step - loss: 1.0917 - accuracy: 0.3689 - val_loss: 1.0988 - val_accuracy: 0.3560\n",
      "Epoch 20/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 1.0906 - accuracy: 0.3731 - val_loss: 1.0991 - val_accuracy: 0.3404\n",
      "Epoch 21/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0905 - accuracy: 0.3781 - val_loss: 1.0998 - val_accuracy: 0.3609\n",
      "Epoch 22/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 1.0887 - accuracy: 0.3827 - val_loss: 1.0992 - val_accuracy: 0.3527\n",
      "Epoch 23/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 1.0872 - accuracy: 0.3851 - val_loss: 1.0944 - val_accuracy: 0.3527\n",
      "Epoch 24/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 1.0871 - accuracy: 0.3887 - val_loss: 1.1093 - val_accuracy: 0.3605\n",
      "Epoch 25/256\n",
      "153/153 [==============================] - 36s 236ms/step - loss: 1.0855 - accuracy: 0.3902 - val_loss: 1.0941 - val_accuracy: 0.3613\n",
      "Epoch 26/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0857 - accuracy: 0.3863 - val_loss: 1.1130 - val_accuracy: 0.3400\n",
      "Epoch 27/256\n",
      "153/153 [==============================] - 35s 231ms/step - loss: 1.0848 - accuracy: 0.3869 - val_loss: 1.1029 - val_accuracy: 0.3306\n",
      "Epoch 28/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0810 - accuracy: 0.3892 - val_loss: 1.0984 - val_accuracy: 0.3540\n",
      "Epoch 29/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0822 - accuracy: 0.3970 - val_loss: 1.1021 - val_accuracy: 0.3568\n",
      "Epoch 30/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0836 - accuracy: 0.3916 - val_loss: 1.0962 - val_accuracy: 0.3572\n",
      "Epoch 31/256\n",
      "153/153 [==============================] - 36s 232ms/step - loss: 1.0797 - accuracy: 0.3976 - val_loss: 1.0955 - val_accuracy: 0.3691\n",
      "Epoch 32/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0798 - accuracy: 0.3961 - val_loss: 1.0977 - val_accuracy: 0.3388\n",
      "Epoch 33/256\n",
      "153/153 [==============================] - 35s 231ms/step - loss: 1.0793 - accuracy: 0.3916 - val_loss: 1.1149 - val_accuracy: 0.3269\n",
      "Epoch 34/256\n",
      "153/153 [==============================] - 35s 231ms/step - loss: 1.0810 - accuracy: 0.3885 - val_loss: 1.0925 - val_accuracy: 0.3757\n",
      "Epoch 35/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 1.0775 - accuracy: 0.4013 - val_loss: 1.0937 - val_accuracy: 0.3572\n",
      "Epoch 36/256\n",
      "153/153 [==============================] - 35s 229ms/step - loss: 1.0780 - accuracy: 0.3994 - val_loss: 1.1022 - val_accuracy: 0.3429\n",
      "Epoch 37/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 1.0759 - accuracy: 0.4063 - val_loss: 1.0918 - val_accuracy: 0.3621\n",
      "Epoch 38/256\n",
      "153/153 [==============================] - 35s 230ms/step - loss: 1.0737 - accuracy: 0.4065 - val_loss: 1.0912 - val_accuracy: 0.3621\n",
      "Epoch 39/256\n",
      "153/153 [==============================] - 35s 231ms/step - loss: 1.0721 - accuracy: 0.4029 - val_loss: 1.0905 - val_accuracy: 0.3638\n",
      "Epoch 40/256\n",
      "153/153 [==============================] - 35s 230ms/step - loss: 1.0715 - accuracy: 0.4124 - val_loss: 1.0891 - val_accuracy: 0.3806\n",
      "Epoch 41/256\n",
      "153/153 [==============================] - 35s 229ms/step - loss: 1.0716 - accuracy: 0.4100 - val_loss: 1.0864 - val_accuracy: 0.3769\n",
      "Epoch 42/256\n",
      "153/153 [==============================] - 35s 232ms/step - loss: 1.0638 - accuracy: 0.4244 - val_loss: 1.0814 - val_accuracy: 0.3830\n",
      "Epoch 43/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 1.0625 - accuracy: 0.4271 - val_loss: 1.0770 - val_accuracy: 0.3978\n",
      "Epoch 44/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 1.0551 - accuracy: 0.4338 - val_loss: 1.0708 - val_accuracy: 0.3957\n",
      "Epoch 45/256\n",
      "153/153 [==============================] - 36s 237ms/step - loss: 1.0542 - accuracy: 0.4375 - val_loss: 1.0663 - val_accuracy: 0.4244\n",
      "Epoch 46/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 1.0405 - accuracy: 0.4504 - val_loss: 1.0540 - val_accuracy: 0.4199\n",
      "Epoch 47/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 1.0200 - accuracy: 0.4780 - val_loss: 1.0071 - val_accuracy: 0.4801\n",
      "Epoch 48/256\n",
      "153/153 [==============================] - 35s 232ms/step - loss: 0.9910 - accuracy: 0.4947 - val_loss: 0.9612 - val_accuracy: 0.5055\n",
      "Epoch 49/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.9342 - accuracy: 0.5397 - val_loss: 0.8567 - val_accuracy: 0.5850\n",
      "Epoch 50/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.8192 - accuracy: 0.5950 - val_loss: 0.8470 - val_accuracy: 0.5379\n",
      "Epoch 51/256\n",
      "153/153 [==============================] - 36s 232ms/step - loss: 0.7442 - accuracy: 0.6242 - val_loss: 0.7916 - val_accuracy: 0.5821\n",
      "Epoch 52/256\n",
      "153/153 [==============================] - 35s 232ms/step - loss: 0.7064 - accuracy: 0.6467 - val_loss: 0.6636 - val_accuracy: 0.6583\n",
      "Epoch 53/256\n",
      "153/153 [==============================] - 35s 230ms/step - loss: 0.6782 - accuracy: 0.6664 - val_loss: 0.6273 - val_accuracy: 0.6923\n",
      "Epoch 54/256\n",
      "153/153 [==============================] - 35s 232ms/step - loss: 0.6926 - accuracy: 0.6577 - val_loss: 0.7295 - val_accuracy: 0.6231\n",
      "Epoch 55/256\n",
      "153/153 [==============================] - 36s 234ms/step - loss: 0.6458 - accuracy: 0.6850 - val_loss: 0.6095 - val_accuracy: 0.6878\n",
      "Epoch 56/256\n",
      "153/153 [==============================] - 35s 232ms/step - loss: 0.6342 - accuracy: 0.6874 - val_loss: 0.7795 - val_accuracy: 0.6534\n",
      "Epoch 57/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 0.6378 - accuracy: 0.6863 - val_loss: 0.6797 - val_accuracy: 0.6309\n",
      "Epoch 58/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.6051 - accuracy: 0.7046 - val_loss: 0.6019 - val_accuracy: 0.6940\n",
      "Epoch 59/256\n",
      "153/153 [==============================] - 37s 242ms/step - loss: 0.6193 - accuracy: 0.6979 - val_loss: 0.6170 - val_accuracy: 0.6936\n",
      "Epoch 60/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.5904 - accuracy: 0.7121 - val_loss: 0.5845 - val_accuracy: 0.7333\n",
      "Epoch 61/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.6156 - accuracy: 0.7036 - val_loss: 0.6929 - val_accuracy: 0.6223\n",
      "Epoch 62/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.5882 - accuracy: 0.7121 - val_loss: 0.6520 - val_accuracy: 0.6903\n",
      "Epoch 63/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.5693 - accuracy: 0.7273 - val_loss: 0.6378 - val_accuracy: 0.7083\n",
      "Epoch 64/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.5887 - accuracy: 0.7141 - val_loss: 0.5959 - val_accuracy: 0.6800\n",
      "Epoch 65/256\n",
      "153/153 [==============================] - 36s 235ms/step - loss: 0.6081 - accuracy: 0.7010 - val_loss: 0.6839 - val_accuracy: 0.6592\n",
      "Epoch 66/256\n",
      "153/153 [==============================] - 36s 239ms/step - loss: 0.5782 - accuracy: 0.7183 - val_loss: 0.6098 - val_accuracy: 0.6653\n",
      "Epoch 67/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.5701 - accuracy: 0.7277 - val_loss: 0.5538 - val_accuracy: 0.7325\n",
      "Epoch 68/256\n",
      "153/153 [==============================] - 36s 232ms/step - loss: 0.5864 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.7042\n",
      "Epoch 69/256\n",
      "153/153 [==============================] - 36s 233ms/step - loss: 0.5595 - accuracy: 0.7326 - val_loss: 0.6726 - val_accuracy: 0.6776\n",
      "Epoch 70/256\n",
      "153/153 [==============================] - 35s 232ms/step - loss: 0.5682 - accuracy: 0.7276 - val_loss: 0.5708 - val_accuracy: 0.7349\n",
      "Epoch 71/256\n",
      "153/153 [==============================] - 38s 247ms/step - loss: 0.5535 - accuracy: 0.7349 - val_loss: 0.6114 - val_accuracy: 0.7063\n",
      "Epoch 72/256\n",
      "153/153 [==============================] - 40s 258ms/step - loss: 0.5660 - accuracy: 0.7253 - val_loss: 0.6261 - val_accuracy: 0.6981\n",
      "Epoch 73/256\n",
      "153/153 [==============================] - 39s 255ms/step - loss: 0.5503 - accuracy: 0.7368 - val_loss: 0.5386 - val_accuracy: 0.7440\n",
      "Epoch 74/256\n",
      "153/153 [==============================] - 39s 252ms/step - loss: 0.5552 - accuracy: 0.7332 - val_loss: 0.5424 - val_accuracy: 0.7337\n",
      "Epoch 75/256\n",
      "153/153 [==============================] - 38s 250ms/step - loss: 0.5432 - accuracy: 0.7410 - val_loss: 0.5350 - val_accuracy: 0.7476\n",
      "Epoch 76/256\n",
      "153/153 [==============================] - 38s 251ms/step - loss: 0.5522 - accuracy: 0.7337 - val_loss: 0.5633 - val_accuracy: 0.7124\n",
      "Epoch 77/256\n",
      "153/153 [==============================] - 38s 250ms/step - loss: 0.5484 - accuracy: 0.7335 - val_loss: 0.5331 - val_accuracy: 0.7362\n",
      "Epoch 78/256\n",
      "153/153 [==============================] - 38s 249ms/step - loss: 0.5403 - accuracy: 0.7399 - val_loss: 0.6304 - val_accuracy: 0.7116\n",
      "Epoch 79/256\n",
      "153/153 [==============================] - 38s 249ms/step - loss: 0.5429 - accuracy: 0.7404 - val_loss: 0.5504 - val_accuracy: 0.7497\n",
      "Epoch 80/256\n",
      "153/153 [==============================] - 38s 246ms/step - loss: 0.5676 - accuracy: 0.7202 - val_loss: 0.5381 - val_accuracy: 0.7497\n",
      "Epoch 81/256\n",
      "153/153 [==============================] - 37s 243ms/step - loss: 0.5423 - accuracy: 0.7454 - val_loss: 0.5852 - val_accuracy: 0.6944\n",
      "Epoch 82/256\n",
      "153/153 [==============================] - 40s 261ms/step - loss: 0.5503 - accuracy: 0.7395 - val_loss: 0.5780 - val_accuracy: 0.7333\n",
      "Epoch 83/256\n",
      "153/153 [==============================] - 40s 261ms/step - loss: 0.5453 - accuracy: 0.7379 - val_loss: 0.5415 - val_accuracy: 0.7444\n",
      "Epoch 84/256\n",
      "153/153 [==============================] - 40s 259ms/step - loss: 0.5350 - accuracy: 0.7474 - val_loss: 0.5265 - val_accuracy: 0.7476\n",
      "Epoch 85/256\n",
      "153/153 [==============================] - 39s 255ms/step - loss: 0.5478 - accuracy: 0.7375 - val_loss: 0.5484 - val_accuracy: 0.7513\n",
      "Epoch 86/256\n",
      "153/153 [==============================] - 39s 256ms/step - loss: 0.5358 - accuracy: 0.7412 - val_loss: 0.5322 - val_accuracy: 0.7386\n",
      "Epoch 87/256\n",
      "153/153 [==============================] - 40s 258ms/step - loss: 0.5255 - accuracy: 0.7502 - val_loss: 0.5236 - val_accuracy: 0.7571\n",
      "Epoch 88/256\n",
      "153/153 [==============================] - 39s 258ms/step - loss: 0.5304 - accuracy: 0.7461 - val_loss: 0.5753 - val_accuracy: 0.7325\n",
      "Epoch 89/256\n",
      "153/153 [==============================] - 40s 261ms/step - loss: 0.5189 - accuracy: 0.7578 - val_loss: 0.6189 - val_accuracy: 0.7050\n",
      "Epoch 90/256\n",
      "153/153 [==============================] - 40s 258ms/step - loss: 0.5144 - accuracy: 0.7558 - val_loss: 0.5410 - val_accuracy: 0.7321\n",
      "Epoch 91/256\n",
      "153/153 [==============================] - 39s 256ms/step - loss: 0.5122 - accuracy: 0.7572 - val_loss: 0.5184 - val_accuracy: 0.7550\n",
      "Epoch 92/256\n",
      "153/153 [==============================] - 40s 259ms/step - loss: 0.5189 - accuracy: 0.7552 - val_loss: 0.5658 - val_accuracy: 0.7452\n",
      "Epoch 93/256\n",
      "153/153 [==============================] - 39s 258ms/step - loss: 0.5173 - accuracy: 0.7543 - val_loss: 0.5398 - val_accuracy: 0.7317\n",
      "Epoch 94/256\n",
      "153/153 [==============================] - 39s 258ms/step - loss: 0.5077 - accuracy: 0.7586 - val_loss: 0.5059 - val_accuracy: 0.7616\n",
      "Epoch 95/256\n",
      "153/153 [==============================] - 40s 259ms/step - loss: 0.5235 - accuracy: 0.7492 - val_loss: 0.5082 - val_accuracy: 0.7517\n",
      "Epoch 96/256\n",
      "153/153 [==============================] - 39s 257ms/step - loss: 0.5000 - accuracy: 0.7663 - val_loss: 0.5354 - val_accuracy: 0.7501\n",
      "Epoch 97/256\n",
      "153/153 [==============================] - 39s 253ms/step - loss: 0.4960 - accuracy: 0.7686 - val_loss: 0.5286 - val_accuracy: 0.7575\n",
      "Epoch 98/256\n",
      "153/153 [==============================] - 39s 252ms/step - loss: 0.5100 - accuracy: 0.7589 - val_loss: 0.5069 - val_accuracy: 0.7595\n",
      "Epoch 99/256\n",
      "153/153 [==============================] - 38s 250ms/step - loss: 0.4946 - accuracy: 0.7702 - val_loss: 0.5198 - val_accuracy: 0.7579\n",
      "Epoch 100/256\n",
      "153/153 [==============================] - 38s 248ms/step - loss: 0.5021 - accuracy: 0.7616 - val_loss: 0.5107 - val_accuracy: 0.7591\n",
      "Epoch 101/256\n",
      "153/153 [==============================] - 38s 246ms/step - loss: 0.5047 - accuracy: 0.7632 - val_loss: 0.5181 - val_accuracy: 0.7489\n",
      "Epoch 102/256\n",
      "153/153 [==============================] - 38s 248ms/step - loss: 0.4874 - accuracy: 0.7740 - val_loss: 0.4943 - val_accuracy: 0.7714\n",
      "Epoch 103/256\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 0.5140 - accuracy: 0.7551 - val_loss: 0.5131 - val_accuracy: 0.7591\n",
      "Epoch 104/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.4831 - accuracy: 0.7786 - val_loss: 0.4950 - val_accuracy: 0.7702\n",
      "Epoch 105/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.4842 - accuracy: 0.7725 - val_loss: 0.5716 - val_accuracy: 0.7300\n",
      "Epoch 106/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.5118 - accuracy: 0.7517 - val_loss: 0.6236 - val_accuracy: 0.7235\n",
      "Epoch 107/256\n",
      "153/153 [==============================] - 37s 241ms/step - loss: 0.4949 - accuracy: 0.7656 - val_loss: 0.5072 - val_accuracy: 0.7644\n",
      "Epoch 108/256\n",
      "153/153 [==============================] - 37s 240ms/step - loss: 0.4773 - accuracy: 0.7786 - val_loss: 0.5253 - val_accuracy: 0.7571\n",
      "Epoch 109/256\n",
      "153/153 [==============================] - 37s 239ms/step - loss: 0.4884 - accuracy: 0.7715 - val_loss: 0.5475 - val_accuracy: 0.7280\n",
      "Epoch 110/256\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.7725Restoring model weights from the end of the best epoch: 102.\n",
      "153/153 [==============================] - 35s 231ms/step - loss: 0.4866 - accuracy: 0.7725 - val_loss: 0.4976 - val_accuracy: 0.7735\n",
      "Epoch 110: early stopping\n"
     ]
    }
   ],
   "source": [
    "# make key hyperparameters accessible and easy to tune\n",
    "BATCH_SIZE = 64\n",
    "LSTM_UNITS = 256\n",
    "\n",
    "N_BATCHES = math.ceil(len(X_train) / BATCH_SIZE)\n",
    "num_features = X_train.shape[2]\n",
    "num_classes = len(labels['label'].unique())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(LSTM_UNITS, input_shape=(SEQUENCE_LENGTH, num_features)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "cp_cb = ModelCheckpoint(filepath='.checkpoints/cp-{epoch:03d}.ckpt', save_weights_only=True, save_freq=8*N_BATCHES)\n",
    "stp_cb = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, min_delta=1e-4, start_from_epoch=32, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=256, batch_size=BATCH_SIZE, callbacks=[cp_cb, stp_cb], validation_data=(X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "model.save(f'models/lstm_{LSTM_UNITS}-seq_{SEQUENCE_LENGTH}-batch_{BATCH_SIZE}.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Best current model `lstm_256-seq_256-batch_64` (75.72%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 215ms/step\n",
      "[[4.5312189e-02 2.4483928e-03 9.5223939e-01]\n",
      " [6.8707055e-01 1.6925095e-01 1.4367852e-01]\n",
      " [3.5855603e-01 5.9688252e-01 4.4561438e-02]\n",
      " [7.1979648e-01 2.1927923e-01 6.0924381e-02]\n",
      " [8.3816811e-02 9.1598350e-01 1.9976469e-04]]\n",
      "96/96 - 6s - loss: 0.4983 - accuracy: 0.7572 - 6s/epoch - 58ms/step\n",
      "Model accuracy: 75.72%\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test[:5]))\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Model accuracy: {:5.2f}%\".format(100 * acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
