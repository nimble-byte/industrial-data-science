{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 08:54:52.984220: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-17 08:54:53.021830: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 08:54:53.021864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 08:54:53.022577: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 08:54:53.027724: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-17 08:54:53.029110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 08:54:54.229479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First step is to ingest all the data we have available and merge them into a flattened datastructure containing all measurements. Indexes are ignored and rewritten to allow all readings to be added to the DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the labels.csv\n",
    "labels = pd.read_csv('labels.csv', index_col=0)\n",
    "labels = labels.sort_values('id')\n",
    "\n",
    "# grab filenames from the data directory\n",
    "filenames = os.listdir('data')\n",
    "filenames.sort()\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# parse and concatenate all csv files into df\n",
    "for filename in filenames:\n",
    "  if filename.endswith('.csv'):\n",
    "    batch = pd.read_csv(os.path.join('data',filename), index_col=0)\n",
    "    batch['batch'] = int(filename.replace('.csv', ''))\n",
    "    dataframes.append(batch)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# clean up original dataframes\n",
    "del dataframes\n",
    "\n",
    "# add label column (if it is not already available)\n",
    "if (not 'label' in df.columns):\n",
    "  df = df.merge(labels, left_on=[\"batch\"], right_on=[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_float(inputstr):\n",
    "  hours, minutes, seconds = map(float, inputstr.split(':'))\n",
    "\n",
    "  # return hours * 3600 + minutes * 60 + seconds\n",
    "  # this is sufficient because hours should always be 0\n",
    "  return minutes * 60 + seconds\n",
    "\n",
    "if (not df['sensorid'].dtype == 'int'):\n",
    "  df['sensorid'] = df['sensorid'].astype('int')\n",
    "if (not df['label'].dtype == 'category'):\n",
    "  df['label'] = df['label'].astype('category')\n",
    "if (not df['zeit'].dtype == 'float64'):\n",
    "  df['zeit'] = df['zeit'].apply(time_to_float)\n",
    "\n",
    "# print(df[:10])\n",
    "# print(labels[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 128\n",
    "\n",
    "sequences = []\n",
    "sequence_labels = []\n",
    "\n",
    "for batch, readings in df.groupby('batch'):\n",
    "  readings = readings.sort_values('zeit')\n",
    "  for i in range(0, len(readings) - SEQUENCE_LENGTH, SEQUENCE_LENGTH):\n",
    "    sequence = readings.iloc[i:i + SEQUENCE_LENGTH]\n",
    "    sequences.append(sequence[['zeit', 'sensorid', 'messwert']].values)\n",
    "    sequence_labels.append(sequence['label'].values[0])\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "sequence_labels = np.array(sequence_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, sequence_labels, test_size=0.2, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 08:55:16.332338: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 08:55:16.332886: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 08:55:16.919938: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30236160 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 32s 100ms/step - loss: 1.1045 - accuracy: 0.3425 - val_loss: 1.1004 - val_accuracy: 0.3362\n",
      "Epoch 2/256\n",
      "308/308 [==============================] - 30s 99ms/step - loss: 1.0975 - accuracy: 0.3581 - val_loss: 1.0940 - val_accuracy: 0.3673\n",
      "Epoch 3/256\n",
      "308/308 [==============================] - 30s 97ms/step - loss: 1.0950 - accuracy: 0.3643 - val_loss: 1.0994 - val_accuracy: 0.3560\n",
      "Epoch 4/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 1.0943 - accuracy: 0.3638 - val_loss: 1.0975 - val_accuracy: 0.3539\n",
      "Epoch 5/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 1.0940 - accuracy: 0.3654 - val_loss: 1.0932 - val_accuracy: 0.3580\n",
      "Epoch 6/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 1.0916 - accuracy: 0.3697 - val_loss: 1.0975 - val_accuracy: 0.3665\n",
      "Epoch 7/256\n",
      "308/308 [==============================] - 30s 99ms/step - loss: 1.0913 - accuracy: 0.3702 - val_loss: 1.0970 - val_accuracy: 0.3671\n",
      "Epoch 8/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 1.0906 - accuracy: 0.3692 - val_loss: 1.0893 - val_accuracy: 0.3744\n",
      "Epoch 9/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 1.0891 - accuracy: 0.3753 - val_loss: 1.0901 - val_accuracy: 0.3895\n",
      "Epoch 10/256\n",
      "308/308 [==============================] - 29s 96ms/step - loss: 1.0877 - accuracy: 0.3756 - val_loss: 1.0891 - val_accuracy: 0.3718\n",
      "Epoch 11/256\n",
      "308/308 [==============================] - 31s 99ms/step - loss: 1.0849 - accuracy: 0.3904 - val_loss: 1.0879 - val_accuracy: 0.3773\n",
      "Epoch 12/256\n",
      "308/308 [==============================] - 33s 108ms/step - loss: 1.0834 - accuracy: 0.3844 - val_loss: 1.0852 - val_accuracy: 0.3787\n",
      "Epoch 13/256\n",
      "308/308 [==============================] - 37s 121ms/step - loss: 1.0805 - accuracy: 0.3914 - val_loss: 1.0807 - val_accuracy: 0.3874\n",
      "Epoch 14/256\n",
      "308/308 [==============================] - 37s 119ms/step - loss: 1.0802 - accuracy: 0.3942 - val_loss: 1.0964 - val_accuracy: 0.3775\n",
      "Epoch 15/256\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 1.0760 - accuracy: 0.3956 - val_loss: 1.0862 - val_accuracy: 0.3911\n",
      "Epoch 16/256\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 1.0738 - accuracy: 0.4014 - val_loss: 1.0747 - val_accuracy: 0.3876\n",
      "Epoch 17/256\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 1.0667 - accuracy: 0.4111 - val_loss: 1.0625 - val_accuracy: 0.4065\n",
      "Epoch 18/256\n",
      "308/308 [==============================] - 36s 116ms/step - loss: 1.0595 - accuracy: 0.4180 - val_loss: 1.0479 - val_accuracy: 0.4193\n",
      "Epoch 19/256\n",
      "308/308 [==============================] - 30s 97ms/step - loss: 1.0460 - accuracy: 0.4319 - val_loss: 1.0362 - val_accuracy: 0.4258\n",
      "Epoch 20/256\n",
      "308/308 [==============================] - 32s 103ms/step - loss: 1.0049 - accuracy: 0.4654 - val_loss: 0.9581 - val_accuracy: 0.4870\n",
      "Epoch 21/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.9499 - accuracy: 0.5023 - val_loss: 0.9736 - val_accuracy: 0.4740\n",
      "Epoch 22/256\n",
      "308/308 [==============================] - 30s 98ms/step - loss: 0.9007 - accuracy: 0.5332 - val_loss: 0.8893 - val_accuracy: 0.5524\n",
      "Epoch 23/256\n",
      "308/308 [==============================] - 32s 103ms/step - loss: 0.8519 - accuracy: 0.5628 - val_loss: 0.8646 - val_accuracy: 0.5488\n",
      "Epoch 24/256\n",
      "308/308 [==============================] - 30s 98ms/step - loss: 0.8430 - accuracy: 0.5729 - val_loss: 0.8725 - val_accuracy: 0.5482\n",
      "Epoch 25/256\n",
      "308/308 [==============================] - 30s 98ms/step - loss: 0.8307 - accuracy: 0.5758 - val_loss: 0.8129 - val_accuracy: 0.5766\n",
      "Epoch 26/256\n",
      "308/308 [==============================] - 30s 97ms/step - loss: 0.7963 - accuracy: 0.5949 - val_loss: 0.7765 - val_accuracy: 0.5965\n",
      "Epoch 27/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.7830 - accuracy: 0.6074 - val_loss: 0.7685 - val_accuracy: 0.6187\n",
      "Epoch 28/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.7676 - accuracy: 0.6122 - val_loss: 0.7755 - val_accuracy: 0.5926\n",
      "Epoch 29/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.7475 - accuracy: 0.6208 - val_loss: 0.7239 - val_accuracy: 0.6361\n",
      "Epoch 30/256\n",
      "308/308 [==============================] - 30s 97ms/step - loss: 0.7466 - accuracy: 0.6265 - val_loss: 0.7328 - val_accuracy: 0.6199\n",
      "Epoch 31/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.7185 - accuracy: 0.6419 - val_loss: 0.7135 - val_accuracy: 0.6412\n",
      "Epoch 32/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.7130 - accuracy: 0.6473 - val_loss: 0.7037 - val_accuracy: 0.6599\n",
      "Epoch 33/256\n",
      "308/308 [==============================] - 29s 96ms/step - loss: 0.7077 - accuracy: 0.6467 - val_loss: 0.6995 - val_accuracy: 0.6585\n",
      "Epoch 34/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6905 - accuracy: 0.6608 - val_loss: 0.6904 - val_accuracy: 0.6690\n",
      "Epoch 35/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.6838 - accuracy: 0.6641 - val_loss: 0.6704 - val_accuracy: 0.6583\n",
      "Epoch 36/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6780 - accuracy: 0.6648 - val_loss: 0.6761 - val_accuracy: 0.6510\n",
      "Epoch 37/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.6775 - accuracy: 0.6651 - val_loss: 0.6769 - val_accuracy: 0.6768\n",
      "Epoch 38/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6684 - accuracy: 0.6684 - val_loss: 0.6651 - val_accuracy: 0.6593\n",
      "Epoch 39/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6723 - accuracy: 0.6682 - val_loss: 0.6572 - val_accuracy: 0.6709\n",
      "Epoch 40/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6787 - accuracy: 0.6657 - val_loss: 0.6656 - val_accuracy: 0.6652\n",
      "Epoch 41/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6627 - accuracy: 0.6733 - val_loss: 0.6872 - val_accuracy: 0.6650\n",
      "Epoch 42/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6750 - accuracy: 0.6654 - val_loss: 0.6634 - val_accuracy: 0.6648\n",
      "Epoch 43/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.6572 - accuracy: 0.6756 - val_loss: 0.6568 - val_accuracy: 0.6764\n",
      "Epoch 44/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6720 - accuracy: 0.6652 - val_loss: 0.6628 - val_accuracy: 0.6595\n",
      "Epoch 45/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.6505 - accuracy: 0.6802 - val_loss: 0.7654 - val_accuracy: 0.6392\n",
      "Epoch 46/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6555 - accuracy: 0.6757 - val_loss: 0.6579 - val_accuracy: 0.6759\n",
      "Epoch 47/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6547 - accuracy: 0.6745 - val_loss: 0.6764 - val_accuracy: 0.6585\n",
      "Epoch 48/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6475 - accuracy: 0.6791 - val_loss: 0.6431 - val_accuracy: 0.6786\n",
      "Epoch 49/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.6495 - accuracy: 0.6778 - val_loss: 0.7388 - val_accuracy: 0.6510\n",
      "Epoch 50/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6367 - accuracy: 0.6877 - val_loss: 0.7975 - val_accuracy: 0.5959\n",
      "Epoch 51/256\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.6452 - accuracy: 0.6815 - val_loss: 0.6819 - val_accuracy: 0.6690\n",
      "Epoch 52/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6481 - accuracy: 0.6795 - val_loss: 0.6354 - val_accuracy: 0.6912\n",
      "Epoch 53/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6459 - accuracy: 0.6803 - val_loss: 0.6647 - val_accuracy: 0.6798\n",
      "Epoch 54/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6337 - accuracy: 0.6860 - val_loss: 0.6789 - val_accuracy: 0.6729\n",
      "Epoch 55/256\n",
      "308/308 [==============================] - 29s 94ms/step - loss: 0.6370 - accuracy: 0.6882 - val_loss: 0.6737 - val_accuracy: 0.6646\n",
      "Epoch 56/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6334 - accuracy: 0.6860 - val_loss: 0.6432 - val_accuracy: 0.6810\n",
      "Epoch 57/256\n",
      "308/308 [==============================] - 29s 93ms/step - loss: 0.6482 - accuracy: 0.6767 - val_loss: 0.6463 - val_accuracy: 0.6806\n",
      "Epoch 58/256\n",
      "308/308 [==============================] - 29s 94ms/step - loss: 0.6303 - accuracy: 0.6890 - val_loss: 0.6347 - val_accuracy: 0.6800\n",
      "Epoch 59/256\n",
      "308/308 [==============================] - 29s 94ms/step - loss: 0.6295 - accuracy: 0.6875 - val_loss: 0.6451 - val_accuracy: 0.6875\n",
      "Epoch 60/256\n",
      "308/308 [==============================] - 29s 95ms/step - loss: 0.6297 - accuracy: 0.6894 - val_loss: 0.6512 - val_accuracy: 0.6662\n",
      "Epoch 61/256\n",
      "308/308 [==============================] - 29s 94ms/step - loss: 0.6262 - accuracy: 0.6897 - val_loss: 0.6386 - val_accuracy: 0.6839\n",
      "Epoch 62/256\n",
      "308/308 [==============================] - 29s 93ms/step - loss: 0.6322 - accuracy: 0.6876 - val_loss: 0.6613 - val_accuracy: 0.6859\n",
      "Epoch 63/256\n",
      "308/308 [==============================] - 29s 94ms/step - loss: 0.6228 - accuracy: 0.6907 - val_loss: 0.6481 - val_accuracy: 0.6863\n",
      "Epoch 64/256\n",
      "308/308 [==============================] - 29s 93ms/step - loss: 0.6280 - accuracy: 0.6893 - val_loss: 0.6592 - val_accuracy: 0.6723\n",
      "Epoch 65/256\n",
      "308/308 [==============================] - 29s 93ms/step - loss: 0.6187 - accuracy: 0.6932 - val_loss: 0.7225 - val_accuracy: 0.6670\n",
      "Epoch 66/256\n",
      "308/308 [==============================] - ETA: 0s - loss: 0.6318 - accuracy: 0.6879Restoring model weights from the end of the best epoch: 58.\n",
      "308/308 [==============================] - 30s 96ms/step - loss: 0.6318 - accuracy: 0.6879 - val_loss: 0.6402 - val_accuracy: 0.6875\n",
      "Epoch 66: early stopping\n"
     ]
    }
   ],
   "source": [
    "# set a bunch of constants that help configure the model and training\n",
    "BATCH_SIZE = 64\n",
    "LSTM_UNITS = 128\n",
    "\n",
    "CHECKPOINT_PATH = '.checkpoints/cp-{epoch:03d}.ckpt'\n",
    "# CHECKPOINT_DIR = os.path.dirname(CHECKPOINT_PATH)\n",
    "\n",
    "N_BATCHES = math.ceil(len(X_train) / BATCH_SIZE)\n",
    "num_features = X_train.shape[2]\n",
    "num_classes = len(labels['label'].unique())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(LSTM_UNITS, input_shape=(SEQUENCE_LENGTH, num_features)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "cp_cb = ModelCheckpoint(filepath=CHECKPOINT_PATH, save_weights_only=True, save_freq=8*N_BATCHES)\n",
    "stp_cb = EarlyStopping(monitor='loss', patience=8, restore_best_weights=True, min_delta=1e-4, start_from_epoch=32, verbose=1)\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=256, batch_size=BATCH_SIZE, callbacks=[cp_cb, stp_cb], validation_data=(X_val, y_val))\n",
    "model.fit(X_train, y_train, epochs=256, batch_size=BATCH_SIZE, callbacks=[cp_cb, stp_cb])\n",
    "\n",
    "# Save Model\n",
    "model.save(f'models/lstm_{LSTM_UNITS}-seq_{SEQUENCE_LENGTH}-batch_{BATCH_SIZE}.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Best current model `lstm_100-seq_128-batch_64` (74.74%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 410ms/step\n",
      "[[0.4175435  0.44573614 0.1367203 ]\n",
      " [0.70361423 0.18829243 0.10809335]\n",
      " [0.34088692 0.6448194  0.0142938 ]\n",
      " [0.39665085 0.5079025  0.09544659]\n",
      " [0.4197015  0.46429542 0.11600314]]\n",
      "193/193 - 5s - loss: 0.6285 - accuracy: 0.6848 - 5s/epoch - 27ms/step\n",
      "Model accuracy: 68.48%\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test[:5]))\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Model accuracy: {:5.2f}%\".format(100 * acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               67584     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67971 (265.51 KB)\n",
      "Trainable params: 67971 (265.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
