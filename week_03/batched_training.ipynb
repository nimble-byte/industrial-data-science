{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 23:43:13.340444: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 23:43:13.360332: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-16 23:43:13.360356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-16 23:43:13.361019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-16 23:43:13.364588: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 23:43:13.365032: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 23:43:13.900473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First step is to ingest all the data we have available and merge them into a flattened datastructure containing all measurements. Indexes are ignored and rewritten to allow all readings to be added to the DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the labels.csv\n",
    "labels = pd.read_csv('labels.csv', index_col=0)\n",
    "labels = labels.sort_values('id')\n",
    "\n",
    "# grab filenames from the data directory\n",
    "filenames = os.listdir('data')\n",
    "filenames.sort()\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# parse and concatenate all csv files into df\n",
    "for filename in filenames:\n",
    "  if filename.endswith('.csv'):\n",
    "    batch = pd.read_csv(os.path.join('data',filename), index_col=0)\n",
    "    batch['batch'] = int(filename.replace('.csv', ''))\n",
    "    dataframes.append(batch)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# clean up original dataframes\n",
    "del dataframes\n",
    "\n",
    "# add label column (if it is not already available)\n",
    "if (not 'label' in df.columns):\n",
    "  df = df.merge(labels, left_on=[\"batch\"], right_on=[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_float(inputstr):\n",
    "  hours, minutes, seconds = map(float, inputstr.split(':'))\n",
    "\n",
    "  # return hours * 3600 + minutes * 60 + seconds\n",
    "  # this is sufficient because hours should always be 0\n",
    "  return minutes * 60 + seconds\n",
    "\n",
    "if (not df['sensorid'].dtype == 'int'):\n",
    "  df['sensorid'] = df['sensorid'].astype('int')\n",
    "if (not df['label'].dtype == 'category'):\n",
    "  df['label'] = df['label'].astype('category')\n",
    "if (not df['zeit'].dtype == 'float64'):\n",
    "  df['zeit'] = df['zeit'].apply(time_to_float)\n",
    "\n",
    "# print(df[:10])\n",
    "# print(labels[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 64\n",
    "\n",
    "sequences = []\n",
    "sequence_labels = []\n",
    "\n",
    "for batch, readings in df.groupby('batch'):\n",
    "  readings = readings.sort_values('zeit')\n",
    "  for i in range(0, len(readings) - SEQUENCE_LENGTH, SEQUENCE_LENGTH):\n",
    "    sequence = readings.iloc[i:i + SEQUENCE_LENGTH]\n",
    "    sequences.append(sequence[['zeit', 'sensorid', 'messwert']].values)\n",
    "    sequence_labels.append(sequence['label'].values[0])\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "sequence_labels = np.array(sequence_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, sequence_labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "618/618 [==============================] - 43s 68ms/step - loss: 1.1046 - accuracy: 0.3452 - val_loss: 1.1011 - val_accuracy: 0.3351\n",
      "Epoch 2/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 1.1013 - accuracy: 0.3447 - val_loss: 1.0976 - val_accuracy: 0.3373\n",
      "Epoch 3/256\n",
      "618/618 [==============================] - 41s 67ms/step - loss: 1.0993 - accuracy: 0.3497 - val_loss: 1.0997 - val_accuracy: 0.3671\n",
      "Epoch 4/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 1.0969 - accuracy: 0.3614 - val_loss: 1.0941 - val_accuracy: 0.3583\n",
      "Epoch 5/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 1.0958 - accuracy: 0.3642 - val_loss: 1.0927 - val_accuracy: 0.3645\n",
      "Epoch 6/256\n",
      "618/618 [==============================] - 41s 67ms/step - loss: 1.0946 - accuracy: 0.3677 - val_loss: 1.0909 - val_accuracy: 0.3783\n",
      "Epoch 7/256\n",
      "618/618 [==============================] - 40s 66ms/step - loss: 1.0931 - accuracy: 0.3712 - val_loss: 1.0916 - val_accuracy: 0.3710\n",
      "Epoch 8/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 1.0906 - accuracy: 0.3788 - val_loss: 1.0904 - val_accuracy: 0.3799\n",
      "Epoch 9/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 1.0911 - accuracy: 0.3768 - val_loss: 1.0902 - val_accuracy: 0.3827\n",
      "Epoch 10/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 1.0902 - accuracy: 0.3809 - val_loss: 1.0887 - val_accuracy: 0.3769\n",
      "Epoch 11/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 1.0876 - accuracy: 0.3864 - val_loss: 1.0837 - val_accuracy: 0.3931\n",
      "Epoch 12/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 1.0842 - accuracy: 0.3916 - val_loss: 1.0826 - val_accuracy: 0.3885\n",
      "Epoch 13/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 1.0755 - accuracy: 0.4047 - val_loss: 1.0713 - val_accuracy: 0.4116\n",
      "Epoch 14/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 1.0510 - accuracy: 0.4368 - val_loss: 1.0022 - val_accuracy: 0.4970\n",
      "Epoch 15/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.9405 - accuracy: 0.5245 - val_loss: 0.8414 - val_accuracy: 0.6005\n",
      "Epoch 16/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.7752 - accuracy: 0.6138 - val_loss: 0.7090 - val_accuracy: 0.6424\n",
      "Epoch 17/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.7180 - accuracy: 0.6428 - val_loss: 0.6942 - val_accuracy: 0.6630\n",
      "Epoch 18/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6985 - accuracy: 0.6564 - val_loss: 0.6823 - val_accuracy: 0.6731\n",
      "Epoch 19/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6913 - accuracy: 0.6585 - val_loss: 0.6567 - val_accuracy: 0.6873\n",
      "Epoch 20/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6846 - accuracy: 0.6597 - val_loss: 0.6774 - val_accuracy: 0.6724\n",
      "Epoch 21/256\n",
      "618/618 [==============================] - 40s 66ms/step - loss: 0.6760 - accuracy: 0.6628 - val_loss: 0.6852 - val_accuracy: 0.6673\n",
      "Epoch 22/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6716 - accuracy: 0.6721 - val_loss: 0.6960 - val_accuracy: 0.6517\n",
      "Epoch 23/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6755 - accuracy: 0.6694 - val_loss: 0.6810 - val_accuracy: 0.6659\n",
      "Epoch 24/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6639 - accuracy: 0.6726 - val_loss: 0.7399 - val_accuracy: 0.6081\n",
      "Epoch 25/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6633 - accuracy: 0.6714 - val_loss: 0.6377 - val_accuracy: 0.6924\n",
      "Epoch 26/256\n",
      "618/618 [==============================] - 40s 66ms/step - loss: 0.6699 - accuracy: 0.6701 - val_loss: 0.6740 - val_accuracy: 0.6737\n",
      "Epoch 27/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6636 - accuracy: 0.6713 - val_loss: 0.6266 - val_accuracy: 0.7043\n",
      "Epoch 28/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6525 - accuracy: 0.6813 - val_loss: 0.6515 - val_accuracy: 0.6877\n",
      "Epoch 29/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6571 - accuracy: 0.6761 - val_loss: 0.6269 - val_accuracy: 0.6970\n",
      "Epoch 30/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6530 - accuracy: 0.6797 - val_loss: 0.6212 - val_accuracy: 0.7006\n",
      "Epoch 31/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6486 - accuracy: 0.6798 - val_loss: 0.6306 - val_accuracy: 0.6922\n",
      "Epoch 32/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6563 - accuracy: 0.6773 - val_loss: 0.6160 - val_accuracy: 0.7005\n",
      "Epoch 33/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6498 - accuracy: 0.6795 - val_loss: 0.6190 - val_accuracy: 0.6974\n",
      "Epoch 34/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6489 - accuracy: 0.6787 - val_loss: 0.6289 - val_accuracy: 0.6899\n",
      "Epoch 35/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6520 - accuracy: 0.6807 - val_loss: 0.7275 - val_accuracy: 0.6364\n",
      "Epoch 36/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6449 - accuracy: 0.6826 - val_loss: 0.6212 - val_accuracy: 0.7028\n",
      "Epoch 37/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6419 - accuracy: 0.6846 - val_loss: 0.6777 - val_accuracy: 0.6551\n",
      "Epoch 38/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6521 - accuracy: 0.6779 - val_loss: 0.6252 - val_accuracy: 0.6891\n",
      "Epoch 39/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6445 - accuracy: 0.6817 - val_loss: 0.6233 - val_accuracy: 0.7009\n",
      "Epoch 40/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6460 - accuracy: 0.6849 - val_loss: 0.6161 - val_accuracy: 0.7067\n",
      "Epoch 41/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6433 - accuracy: 0.6839 - val_loss: 0.6187 - val_accuracy: 0.7035\n",
      "Epoch 42/256\n",
      "618/618 [==============================] - 41s 67ms/step - loss: 0.6410 - accuracy: 0.6863 - val_loss: 0.7000 - val_accuracy: 0.6391\n",
      "Epoch 43/256\n",
      "618/618 [==============================] - 41s 67ms/step - loss: 0.6392 - accuracy: 0.6875 - val_loss: 0.6208 - val_accuracy: 0.6995\n",
      "Epoch 44/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6369 - accuracy: 0.6885 - val_loss: 0.6277 - val_accuracy: 0.6958\n",
      "Epoch 45/256\n",
      "618/618 [==============================] - 42s 67ms/step - loss: 0.6357 - accuracy: 0.6918 - val_loss: 0.6678 - val_accuracy: 0.6789\n",
      "Epoch 46/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6358 - accuracy: 0.6890 - val_loss: 0.6428 - val_accuracy: 0.6926\n",
      "Epoch 47/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6279 - accuracy: 0.6947 - val_loss: 0.6173 - val_accuracy: 0.7066\n",
      "Epoch 48/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6412 - accuracy: 0.6885 - val_loss: 0.6052 - val_accuracy: 0.7109\n",
      "Epoch 49/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6302 - accuracy: 0.6906 - val_loss: 0.6127 - val_accuracy: 0.6963\n",
      "Epoch 50/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6327 - accuracy: 0.6934 - val_loss: 0.6482 - val_accuracy: 0.6919\n",
      "Epoch 51/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6301 - accuracy: 0.6957 - val_loss: 0.7108 - val_accuracy: 0.6406\n",
      "Epoch 52/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6315 - accuracy: 0.6929 - val_loss: 0.6056 - val_accuracy: 0.7128\n",
      "Epoch 53/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6265 - accuracy: 0.6970 - val_loss: 0.6643 - val_accuracy: 0.6825\n",
      "Epoch 54/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6259 - accuracy: 0.6975 - val_loss: 0.6390 - val_accuracy: 0.6972\n",
      "Epoch 55/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6236 - accuracy: 0.6995 - val_loss: 0.6027 - val_accuracy: 0.7129\n",
      "Epoch 56/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6295 - accuracy: 0.6941 - val_loss: 0.6034 - val_accuracy: 0.7100\n",
      "Epoch 57/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6237 - accuracy: 0.6975 - val_loss: 0.5966 - val_accuracy: 0.7140\n",
      "Epoch 58/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6244 - accuracy: 0.7027 - val_loss: 0.6670 - val_accuracy: 0.6741\n",
      "Epoch 59/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6258 - accuracy: 0.6988 - val_loss: 0.6171 - val_accuracy: 0.7062\n",
      "Epoch 60/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6207 - accuracy: 0.7002 - val_loss: 0.6009 - val_accuracy: 0.7184\n",
      "Epoch 61/256\n",
      "618/618 [==============================] - 40s 65ms/step - loss: 0.6233 - accuracy: 0.6969 - val_loss: 0.6174 - val_accuracy: 0.7039\n",
      "Epoch 62/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6245 - accuracy: 0.7000 - val_loss: 0.6823 - val_accuracy: 0.6769\n",
      "Epoch 63/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6257 - accuracy: 0.6990 - val_loss: 0.6061 - val_accuracy: 0.7079\n",
      "Epoch 64/256\n",
      "618/618 [==============================] - 41s 66ms/step - loss: 0.6252 - accuracy: 0.6958 - val_loss: 0.6022 - val_accuracy: 0.7132\n",
      "Epoch 65/256\n",
      "617/618 [============================>.] - ETA: 0s - loss: 0.6145 - accuracy: 0.7032Restoring model weights from the end of the best epoch: 57.\n",
      "618/618 [==============================] - 41s 67ms/step - loss: 0.6145 - accuracy: 0.7032 - val_loss: 0.6603 - val_accuracy: 0.6888\n",
      "Epoch 65: early stopping\n"
     ]
    }
   ],
   "source": [
    "# set a bunch of constants that help configure the model and training\n",
    "BATCH_SIZE = 64\n",
    "LSTM_UNITS = 256\n",
    "\n",
    "CHECKPOINT_PATH = '.checkpoints/cp-{epoch:03d}.ckpt'\n",
    "# CHECKPOINT_DIR = os.path.dirname(CHECKPOINT_PATH)\n",
    "\n",
    "N_BATCHES = math.ceil(len(X_train) / BATCH_SIZE)\n",
    "num_features = X_train.shape[2]\n",
    "num_classes = len(labels['label'].unique())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(LSTM_UNITS, input_shape=(SEQUENCE_LENGTH, num_features)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "cp_cb = ModelCheckpoint(filepath=CHECKPOINT_PATH, save_weights_only=True, save_freq=8*N_BATCHES)\n",
    "stp_cb = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, min_delta=1e-4, start_from_epoch=32, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=256, batch_size=BATCH_SIZE, callbacks=[cp_cb, stp_cb], validation_data=(X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "model.save(f'models/lstm_{LSTM_UNITS}-seq_{SEQUENCE_LENGTH}-batch_{BATCH_SIZE}.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Best current model `lstm_100-seq_128-batch_64` (74.74%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 214ms/step\n",
      "[[4.8466197e-01 3.7249166e-01 1.4284633e-01]\n",
      " [1.8934818e-01 8.0996621e-01 6.8551704e-04]\n",
      " [3.5952237e-01 6.3849515e-01 1.9824610e-03]\n",
      " [3.5528547e-01 5.3132200e-01 1.1339250e-01]\n",
      " [7.2025174e-01 2.3314826e-01 4.6599906e-02]]\n",
      "386/386 - 6s - loss: 0.6048 - accuracy: 0.7063 - 6s/epoch - 17ms/step\n",
      "Model accuracy: 70.63%\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test[:5]))\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Model accuracy: {:5.2f}%\".format(100 * acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
